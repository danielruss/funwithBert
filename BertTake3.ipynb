{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this time working with:  https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=SCZWZtKxObjh\n",
    "\n",
    "This uses an old version of bert for tf v1...  using\n",
    "\n",
    "https://pypi.org/project/bert-for-tf2/\n",
    "and\n",
    "https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert\n",
    "\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import hashlib\n",
    "\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45380, 2)\n",
      "(4620, 2)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "movie_reviews = pd.read_csv(\"/Users/druss/Downloads/IMDB Dataset.csv\")\n",
    "movie_reviews.shape\n",
    "\n",
    "# preprocess the data\n",
    "reviews = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    reviews.append(preprocess_text(sen))\n",
    "\n",
    "# get the labels...\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, movie_reviews['sentiment'])))\n",
    "\n",
    "# tokenzize the data...\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
    "\n",
    "# create a function for tokenizing reviews...\n",
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))\n",
    "\n",
    "tokenized_reviews = [tokenize_reviews(review) for review in reviews]\n",
    "\n",
    "random.seed(4);\n",
    "reviews_with_len = [[review, y[i], len(review)]\n",
    "                 for i, review in enumerate(tokenized_reviews)]\n",
    "random.shuffle(reviews_with_len)\n",
    "\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "\n",
    "#processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
    "#BATCH_SIZE = 32\n",
    "#batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "\n",
    "#TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "#TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "#batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "#test_data = batched_dataset.take(TEST_BATCHES)\n",
    "#train_data = batched_dataset.skip(TEST_BATCHES)\n",
    "\n",
    "\n",
    "zz = pd.DataFrame(list(zip(reviews,tokenized_reviews,y)), columns=(\"text\",\"tokens\",\"label\"))\n",
    "zz[\"len\"] = [ len(x) for x in zz[\"tokens\"] ]\n",
    "\n",
    "# split the data into Train/test based on the md5 hash...\n",
    "zz[\"hash\"] = [ hashlib.md5(x.encode('ascii')).hexdigest() for x in zz[\"text\"] ]\n",
    "zz[\"Test\"] = [ (int(x,16) % 100 > 90) for x in zz[\"hash\"]]\n",
    "train_data = zz[zz[\"Test\"] != True]\n",
    "test_data = zz[zz[\"Test\"] == True]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok following the step in BertTake2,  we are now at the point where we are ready to build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45380, 6)\n",
      "(4620, 6)\n"
     ]
    }
   ],
   "source": [
    "zz = pd.DataFrame(list(zip(reviews,tokenized_reviews,y)), columns=(\"text\",\"tokens\",\"label\"))\n",
    "zz[\"len\"] = [ len(x) for x in zz[\"tokens\"] ]\n",
    "\n",
    "# split the data into Train/test based on the md5 hash...\n",
    "zz[\"hash\"] = [ hashlib.md5(x.encode('ascii')).hexdigest() for x in zz[\"text\"] ]\n",
    "zz[\"Test\"] = [ (int(x,16) % 100 > 90) for x in zz[\"hash\"]]\n",
    "train_data = zz[zz[\"Test\"] != True]\n",
    "test_data = zz[zz[\"Test\"] == True]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "                                                     text  \\\n",
      "0      One of the other reviewers has mentioned that ...   \n",
      "1      A wonderful little production The filming tech...   \n",
      "2      I thought this was wonderful way to spend time...   \n",
      "3      Basically there a family where little boy Jake...   \n",
      "4      Petter Mattei Love in the Time of Money is vis...   \n",
      "...                                                  ...   \n",
      "49995  I thought this movie did down right good job I...   \n",
      "49996  Bad plot bad dialogue bad acting idiotic direc...   \n",
      "49997  I am Catholic taught in parochial elementary s...   \n",
      "49998  I going to have to disagree with the previous ...   \n",
      "49999  No one expects the Star Trek movies to be high...   \n",
      "\n",
      "                                                  tokens  label  len  \\\n",
      "0      [2028, 1997, 1996, 2060, 15814, 2038, 3855, 20...      1  318   \n",
      "1      [1037, 6919, 2210, 2537, 1996, 7467, 6028, 200...      1  167   \n",
      "2      [1045, 2245, 2023, 2001, 6919, 2126, 2000, 524...      1  163   \n",
      "3      [10468, 2045, 1037, 2155, 2073, 2210, 2879, 51...      0  129   \n",
      "4      [9004, 3334, 4717, 7416, 2293, 1999, 1996, 205...      1  238   \n",
      "...                                                  ...    ...  ...   \n",
      "49995  [1045, 2245, 2023, 3185, 2106, 2091, 2157, 220...      1  187   \n",
      "49996  [2919, 5436, 2919, 7982, 2919, 3772, 10041, 25...      0  117   \n",
      "49997  [1045, 2572, 3234, 4036, 1999, 28773, 4732, 28...      0  227   \n",
      "49998  [1045, 2183, 2000, 2031, 2000, 21090, 2007, 19...      0  242   \n",
      "49999  [2053, 2028, 24273, 1996, 2732, 10313, 5691, 2...      0  130   \n",
      "\n",
      "                                   hash   Test  \n",
      "0      224a45b0a0587058260659bca7e5e017  False  \n",
      "1      eb34a11df84804f9e8a12566067b7b77  False  \n",
      "2      d8c0c80ad211ed7b4b7546ba2fd91d13  False  \n",
      "3      f096d3e60f0c1cd633775dae69ddbcd8  False  \n",
      "4      19bc24809030f3a49fc100d06f609d1a  False  \n",
      "...                                 ...    ...  \n",
      "49995  4e436d62ebd850a3736f09cbf403f2e2  False  \n",
      "49996  ac57048252a834440dbb2d35e6909b4e  False  \n",
      "49997  5318d6a40115c8ed55525990d91aac89  False  \n",
      "49998  43ea31cbfa56a3b0c429caae95a244c5  False  \n",
      "49999  c47a1883c468b867d024cb69ba49c38c  False  \n",
      "\n",
      "[45380 rows x 6 columns]\n",
      "test:\n",
      "                                                     text  \\\n",
      "6      I sure would like to see resurrection of up da...   \n",
      "42     Of all the films have seen this one The Rage h...   \n",
      "49     Average and surprisingly tame Fulci giallo whi...   \n",
      "63     Besides being boring the scenes were oppressiv...   \n",
      "70     Caddyshack Two is good movie by itself but com...   \n",
      "...                                                  ...   \n",
      "49959  My thoughts on the movie It was not good not g...   \n",
      "49963  If you like really shocking movies this is for...   \n",
      "49964  I saw this last week during Bruce Campbell boo...   \n",
      "49983  I loved it having been fan of the original ser...   \n",
      "49991  Les Visiteurs the first movie about the mediev...   \n",
      "\n",
      "                                                  tokens  label  len  \\\n",
      "6      [1045, 2469, 2052, 2066, 2000, 2156, 15218, 19...      1  155   \n",
      "42     [1997, 2035, 1996, 3152, 2031, 2464, 2023, 202...      0  176   \n",
      "49     [2779, 1998, 10889, 24763, 11865, 15472, 2072,...      0  109   \n",
      "63     [4661, 2108, 11771, 1996, 5019, 2020, 28558, 1...      0   52   \n",
      "70     [28353, 5149, 7377, 3600, 2048, 2003, 2204, 31...      0  244   \n",
      "...                                                  ...    ...  ...   \n",
      "49959  [2026, 4301, 2006, 1996, 3185, 2009, 2001, 202...      0  600   \n",
      "49963  [2065, 2017, 2066, 2428, 16880, 5691, 2023, 20...      0   65   \n",
      "49964  [1045, 2387, 2023, 2197, 2733, 2076, 5503, 606...      1  227   \n",
      "49983  [1045, 3866, 2009, 2383, 2042, 5470, 1997, 199...      1  127   \n",
      "49991  [4649, 3942, 26744, 1996, 2034, 3185, 2055, 19...      0  266   \n",
      "\n",
      "                                   hash  Test  \n",
      "6      c5c4cf73513dcc56ffa4407cb8f122a4  True  \n",
      "42     918df352afa5d7e2a748646b72ce60a7  True  \n",
      "49     a413870abe8e351ce249fe335d9f49c3  True  \n",
      "63     d6a8db3df658403e551729e62e252449  True  \n",
      "70     c88650c3f57fa56441954230f7f6bfd1  True  \n",
      "...                                 ...   ...  \n",
      "49959  990a38643201beeec2f631f932a1089d  True  \n",
      "49963  6ef33ea069803a156c0b36352559a890  True  \n",
      "49964  8f36c2e162da5eadbbc0e7e6046b869b  True  \n",
      "49983  d365dcede861bf5ae05584760b70388d  True  \n",
      "49991  81020ce854a475965055470d4305e9ab  True  \n",
      "\n",
      "[4620 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\\n\",train_data)\n",
    "print(\"test:\\n\",test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/druss/Downloads/uncased_L-12_H-768_A-12\"\n",
    "\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: /Users/druss/Downloads/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x69318aad0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "max_seq_len = 128\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "# using the default token_type/segment id 0\n",
    "output = l_bert(l_input_ids)                              # output: [batch_size, max_seq_len, hidden_size]\n",
    "model = keras.Model(inputs=l_input_ids, outputs=output)\n",
    "model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "bert_ckpt_file   = os.path.join(model_dir, \"bert_model.ckpt\")\n",
    "bert.load_stock_weights(l_bert, bert_ckpt_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
