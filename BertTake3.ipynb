{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this time working with:  https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=SCZWZtKxObjh\n",
    "\n",
    "This uses an old version of bert for tf v1...  using\n",
    "\n",
    "https://pypi.org/project/bert-for-tf2/\n",
    "and\n",
    "https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.17600000001039007  ms.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert\n",
    "\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import hashlib\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "t0 = time.process_time()\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "t1 = time.process_time()\n",
    "print(\"time: \",(t1-t0)*1000,\" ms.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45380, 6)\n",
      "(4620, 6)\n",
      "time:  166.75956399999995  sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time.process_time()\n",
    "\n",
    "# load the data\n",
    "movie_reviews = pd.read_csv(\"/Users/druss/Downloads/IMDB Dataset.csv\")\n",
    "movie_reviews.shape\n",
    "\n",
    "# preprocess the data\n",
    "reviews = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    reviews.append(preprocess_text(sen))\n",
    "\n",
    "# get the labels...\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, movie_reviews['sentiment'])))\n",
    "\n",
    "# tokenzize the data...\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
    "\n",
    "# create a function for tokenizing reviews...\n",
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))\n",
    "\n",
    "tokenized_reviews = [tokenize_reviews(review) for review in reviews]\n",
    "\n",
    "random.seed(4);\n",
    "reviews_with_len = [[review, y[i], len(review)]\n",
    "                 for i, review in enumerate(tokenized_reviews)]\n",
    "random.shuffle(reviews_with_len)\n",
    "\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "\n",
    "#processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
    "#BATCH_SIZE = 32\n",
    "#batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "\n",
    "#TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "#TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "#batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "#test_data = batched_dataset.take(TEST_BATCHES)\n",
    "#train_data = batched_dataset.skip(TEST_BATCHES)\n",
    "\n",
    "\n",
    "zz=pd.DataFrame( {\n",
    "    \"text\":pd.Series(reviews), \n",
    "    \"tokens\":pd.Series(tokenized_reviews), \n",
    "    \"label\":pd.Series(y)\n",
    "})\n",
    "zz[\"len\"] = [ len(x) for x in zz[\"tokens\"] ]\n",
    "\n",
    "# split the data into Train/test based on the md5 hash...\n",
    "zz[\"hash\"] = [ hashlib.md5(x.encode('ascii')).hexdigest() for x in zz[\"text\"] ]\n",
    "zz[\"Test\"] = [ (int(x,16) % 100 > 90) for x in zz[\"hash\"]]\n",
    "train_data = zz[zz[\"Test\"] != True].copy()\n",
    "test_data = zz[zz[\"Test\"] == True].copy()\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "t1 = time.process_time()\n",
    "print(\"time: \",(t1-t0),\" sec\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok following the step in BertTake2,  we are now at the point where we are ready to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter both the training/testing data so that no input has more than 300 tokens...\n",
    "300 was chosen be 75% of the Test/Train data has less than 300 tokens.\n",
    "\n",
    "consider truncating the tokens to the first 300..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45380.000000\n",
       "mean       236.185963\n",
       "std        177.779214\n",
       "min          6.000000\n",
       "25%        127.000000\n",
       "50%        176.000000\n",
       "75%        286.000000\n",
       "max       2615.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x6c2427bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "      <th>hash</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see resurrection of up da...</td>\n",
       "      <td>[1045, 2469, 2052, 2066, 2000, 2156, 15218, 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>c5c4cf73513dcc56ffa4407cb8f122a4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Of all the films have seen this one The Rage h...</td>\n",
       "      <td>[1997, 2035, 1996, 3152, 2031, 2464, 2023, 202...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>918df352afa5d7e2a748646b72ce60a7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Average and surprisingly tame Fulci giallo whi...</td>\n",
       "      <td>[2779, 1998, 10889, 24763, 11865, 15472, 2072,...</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>a413870abe8e351ce249fe335d9f49c3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Besides being boring the scenes were oppressiv...</td>\n",
       "      <td>[4661, 2108, 11771, 1996, 5019, 2020, 28558, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>d6a8db3df658403e551729e62e252449</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Caddyshack Two is good movie by itself but com...</td>\n",
       "      <td>[28353, 5149, 7377, 3600, 2048, 2003, 2204, 31...</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>c88650c3f57fa56441954230f7f6bfd1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49959</th>\n",
       "      <td>My thoughts on the movie It was not good not g...</td>\n",
       "      <td>[2026, 4301, 2006, 1996, 3185, 2009, 2001, 202...</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>990a38643201beeec2f631f932a1089d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49963</th>\n",
       "      <td>If you like really shocking movies this is for...</td>\n",
       "      <td>[2065, 2017, 2066, 2428, 16880, 5691, 2023, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>6ef33ea069803a156c0b36352559a890</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49964</th>\n",
       "      <td>I saw this last week during Bruce Campbell boo...</td>\n",
       "      <td>[1045, 2387, 2023, 2197, 2733, 2076, 5503, 606...</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>8f36c2e162da5eadbbc0e7e6046b869b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>I loved it having been fan of the original ser...</td>\n",
       "      <td>[1045, 3866, 2009, 2383, 2042, 5470, 1997, 199...</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>d365dcede861bf5ae05584760b70388d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>Les Visiteurs the first movie about the mediev...</td>\n",
       "      <td>[4649, 3942, 26744, 1996, 2034, 3185, 2055, 19...</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>81020ce854a475965055470d4305e9ab</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "6      I sure would like to see resurrection of up da...   \n",
       "42     Of all the films have seen this one The Rage h...   \n",
       "49     Average and surprisingly tame Fulci giallo whi...   \n",
       "63     Besides being boring the scenes were oppressiv...   \n",
       "70     Caddyshack Two is good movie by itself but com...   \n",
       "...                                                  ...   \n",
       "49959  My thoughts on the movie It was not good not g...   \n",
       "49963  If you like really shocking movies this is for...   \n",
       "49964  I saw this last week during Bruce Campbell boo...   \n",
       "49983  I loved it having been fan of the original ser...   \n",
       "49991  Les Visiteurs the first movie about the mediev...   \n",
       "\n",
       "                                                  tokens  label  len  \\\n",
       "6      [1045, 2469, 2052, 2066, 2000, 2156, 15218, 19...      1  155   \n",
       "42     [1997, 2035, 1996, 3152, 2031, 2464, 2023, 202...      0  176   \n",
       "49     [2779, 1998, 10889, 24763, 11865, 15472, 2072,...      0  109   \n",
       "63     [4661, 2108, 11771, 1996, 5019, 2020, 28558, 1...      0   52   \n",
       "70     [28353, 5149, 7377, 3600, 2048, 2003, 2204, 31...      0  244   \n",
       "...                                                  ...    ...  ...   \n",
       "49959  [2026, 4301, 2006, 1996, 3185, 2009, 2001, 202...      0  600   \n",
       "49963  [2065, 2017, 2066, 2428, 16880, 5691, 2023, 20...      0   65   \n",
       "49964  [1045, 2387, 2023, 2197, 2733, 2076, 5503, 606...      1  227   \n",
       "49983  [1045, 3866, 2009, 2383, 2042, 5470, 1997, 199...      1  127   \n",
       "49991  [4649, 3942, 26744, 1996, 2034, 3185, 2055, 19...      0  266   \n",
       "\n",
       "                                   hash  Test  \n",
       "6      c5c4cf73513dcc56ffa4407cb8f122a4  True  \n",
       "42     918df352afa5d7e2a748646b72ce60a7  True  \n",
       "49     a413870abe8e351ce249fe335d9f49c3  True  \n",
       "63     d6a8db3df658403e551729e62e252449  True  \n",
       "70     c88650c3f57fa56441954230f7f6bfd1  True  \n",
       "...                                 ...   ...  \n",
       "49959  990a38643201beeec2f631f932a1089d  True  \n",
       "49963  6ef33ea069803a156c0b36352559a890  True  \n",
       "49964  8f36c2e162da5eadbbc0e7e6046b869b  True  \n",
       "49983  d365dcede861bf5ae05584760b70388d  True  \n",
       "49991  81020ce854a475965055470d4305e9ab  True  \n",
       "\n",
       "[4620 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    4620.000000\n",
       "mean      239.057143\n",
       "std       182.112432\n",
       "min        17.000000\n",
       "25%       127.000000\n",
       "50%       176.000000\n",
       "75%       291.250000\n",
       "max      1768.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x6c2427bd0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = train_data.groupby(\"len\").size()\n",
    "display(train_data[\"len\"].describe())\n",
    "display(tmp.plot())\n",
    "\n",
    "\n",
    "display(test_data)\n",
    "tmp1 = test_data.groupby(\"len\").size()\n",
    "display(test_data[\"len\"].describe())\n",
    "tmp1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45380, 6)\n",
      "(4620, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "      <th>hash</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>howdy</td>\n",
       "      <td>[2028, 1997, 1996, 2060, 15814, 2038, 3855, 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>224a45b0a0587058260659bca7e5e017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>[1037, 6919, 2210, 2537, 1996, 7467, 6028, 200...</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>eb34a11df84804f9e8a12566067b7b77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>[1045, 2245, 2023, 2001, 6919, 2126, 2000, 524...</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>d8c0c80ad211ed7b4b7546ba2fd91d13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>[10468, 2045, 1037, 2155, 2073, 2210, 2879, 51...</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>f096d3e60f0c1cd633775dae69ddbcd8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>[9004, 3334, 4717, 7416, 2293, 1999, 1996, 205...</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>19bc24809030f3a49fc100d06f609d1a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did down right good job I...</td>\n",
       "      <td>[1045, 2245, 2023, 3185, 2106, 2091, 2157, 220...</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>4e436d62ebd850a3736f09cbf403f2e2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[2919, 5436, 2919, 7982, 2919, 3772, 10041, 25...</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>ac57048252a834440dbb2d35e6909b4e</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am Catholic taught in parochial elementary s...</td>\n",
       "      <td>[1045, 2572, 3234, 4036, 1999, 28773, 4732, 28...</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>5318d6a40115c8ed55525990d91aac89</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I going to have to disagree with the previous ...</td>\n",
       "      <td>[1045, 2183, 2000, 2031, 2000, 21090, 2007, 19...</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>43ea31cbfa56a3b0c429caae95a244c5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>[2053, 2028, 24273, 1996, 2732, 10313, 5691, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>c47a1883c468b867d024cb69ba49c38c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45380 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                                                  howdy   \n",
       "1      A wonderful little production The filming tech...   \n",
       "2      I thought this was wonderful way to spend time...   \n",
       "3      Basically there a family where little boy Jake...   \n",
       "4      Petter Mattei Love in the Time of Money is vis...   \n",
       "...                                                  ...   \n",
       "49995  I thought this movie did down right good job I...   \n",
       "49996  Bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  I am Catholic taught in parochial elementary s...   \n",
       "49998  I going to have to disagree with the previous ...   \n",
       "49999  No one expects the Star Trek movies to be high...   \n",
       "\n",
       "                                                  tokens  label  len  \\\n",
       "0      [2028, 1997, 1996, 2060, 15814, 2038, 3855, 20...      1  318   \n",
       "1      [1037, 6919, 2210, 2537, 1996, 7467, 6028, 200...      1  167   \n",
       "2      [1045, 2245, 2023, 2001, 6919, 2126, 2000, 524...      1  163   \n",
       "3      [10468, 2045, 1037, 2155, 2073, 2210, 2879, 51...      0  129   \n",
       "4      [9004, 3334, 4717, 7416, 2293, 1999, 1996, 205...      1  238   \n",
       "...                                                  ...    ...  ...   \n",
       "49995  [1045, 2245, 2023, 3185, 2106, 2091, 2157, 220...      1  187   \n",
       "49996  [2919, 5436, 2919, 7982, 2919, 3772, 10041, 25...      0  117   \n",
       "49997  [1045, 2572, 3234, 4036, 1999, 28773, 4732, 28...      0  227   \n",
       "49998  [1045, 2183, 2000, 2031, 2000, 21090, 2007, 19...      0  242   \n",
       "49999  [2053, 2028, 24273, 1996, 2732, 10313, 5691, 2...      0  130   \n",
       "\n",
       "                                   hash   Test  \n",
       "0      224a45b0a0587058260659bca7e5e017  False  \n",
       "1      eb34a11df84804f9e8a12566067b7b77  False  \n",
       "2      d8c0c80ad211ed7b4b7546ba2fd91d13  False  \n",
       "3      f096d3e60f0c1cd633775dae69ddbcd8  False  \n",
       "4      19bc24809030f3a49fc100d06f609d1a  False  \n",
       "...                                 ...    ...  \n",
       "49995  4e436d62ebd850a3736f09cbf403f2e2  False  \n",
       "49996  ac57048252a834440dbb2d35e6909b4e  False  \n",
       "49997  5318d6a40115c8ed55525990d91aac89  False  \n",
       "49998  43ea31cbfa56a3b0c429caae95a244c5  False  \n",
       "49999  c47a1883c468b867d024cb69ba49c38c  False  \n",
       "\n",
       "[45380 rows x 6 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( {\n",
    "    \"text\":pd.Series(reviews), \n",
    "    \"tokens\":pd.Series(tokenized_reviews), \n",
    "    \"label\":pd.Series(y)\n",
    "})\n",
    "zz[\"len\"] = [ len(x) for x in zz[\"tokens\"] ]\n",
    "\n",
    "# split the data into Train/test based on the md5 hash...\n",
    "zz[\"hash\"] = [ hashlib.md5(x.encode('ascii')).hexdigest() for x in zz[\"text\"] ]\n",
    "zz[\"Test\"] = [ (int(x,16) % 100 > 90) for x in zz[\"hash\"]]\n",
    "train_data = zz[zz[\"Test\"] != True].copy()\n",
    "test_data = zz[zz[\"Test\"] == True].copy()\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data.iloc[0,0]=\"howdy\"\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "         ..\n",
       "49995   NaN\n",
       "49996   NaN\n",
       "49997   NaN\n",
       "49998   NaN\n",
       "49999   NaN\n",
       "Name: Test, Length: 50000, dtype: float64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data = train_data[ train_data[\"len\"] < 300]\n",
    "#test_data = test_data[ test_data[\"len\"]<300]\n",
    "train_data = zz[zz[\"Test\"] != True].copy()\n",
    "test_data = zz[zz[\"Test\"] == True].copy()\n",
    "\n",
    "def addSpecialTokens(lst,maxValues):\n",
    "    lst=lst[:maxValues-3]\n",
    "    lst.insert(0,101)\n",
    "    lst.append(102)\n",
    "\n",
    "##test_data[\"tokens\"].apply(lambda x:x.insert(0,1))\n",
    "test_data[\"tokens\"].apply(addSpecialTokens,args=(300,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.00498800000002575  sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time.process_time()\n",
    "model_dir = \"/Users/druss/Downloads/uncased_L-12_H-768_A-12\"\n",
    "\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "t1 = time.process_time()\n",
    "print(\"time: \",(t1-t0),\" sec\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: /Users/druss/Downloads/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x6a9a18450> (prefix:bert_5). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "time:  3.6569389999999657  sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time.process_time()\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "max_seq_len = 300\n",
    "l_input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "l_token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "# using the default token_type/segment id 0\n",
    "output = l_bert(l_input_ids)                              # output: [batch_size, max_seq_len, hidden_size]\n",
    "model = keras.Model(inputs=l_input_ids, outputs=output)\n",
    "model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "bert_ckpt_file   = os.path.join(model_dir, \"bert_model.ckpt\")\n",
    "bert.load_stock_weights(l_bert, bert_ckpt_file)\n",
    "\n",
    "t1 = time.process_time()\n",
    "print(\"time: \",(t1-t0),\" sec\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we now have the pretrained bert model loaded...  we need get the input in a format bert can ingest.  We need masks to ignore tokens in the sentence that are longer than the max seq length. (which we define in the cell above as 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convert_tokens_to_ids() missing 1 required positional argument: 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-0a8cbdc8ac4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CLS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-180-d31cfb8180a7>\u001b[0m in \u001b[0;36mget_ids\u001b[0;34m(tokens, tokenizer, max_seq_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"\"\"Token ids from Tokenizer vocab\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: convert_tokens_to_ids() missing 1 required positional argument: 'tokens'"
     ]
    }
   ],
   "source": [
    "get_ids([\"CLS\"],BertTokenizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1        [102, 1037, 6919, 2210, 2537, 1996, 7467, 6028...\n",
       "2        [102, 1045, 2245, 2023, 2001, 6919, 2126, 2000...\n",
       "3        [102, 10468, 2045, 1037, 2155, 2073, 2210, 287...\n",
       "4        [102, 9004, 3334, 4717, 7416, 2293, 1999, 1996...\n",
       "5        [102, 2763, 2026, 2035, 2051, 5440, 3185, 2466...\n",
       "                               ...                        \n",
       "49995    [102, 1045, 2245, 2023, 3185, 2106, 2091, 2157...\n",
       "49996    [102, 2919, 5436, 2919, 7982, 2919, 3772, 1004...\n",
       "49997    [102, 1045, 2572, 3234, 4036, 1999, 28773, 473...\n",
       "49998    [102, 1045, 2183, 2000, 2031, 2000, 21090, 200...\n",
       "49999    [102, 2053, 2028, 24273, 1996, 2732, 10313, 56...\n",
       "Name: tokens, Length: 34829, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_ids(tokens=[\"[CLS]\",\"[SEP]\"]))\n",
    "train_data[\"tokens\"].apply(lambda x:x.insert(0,102))\n",
    "\n",
    "train_data[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
